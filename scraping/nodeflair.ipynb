{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping NodeFlair Job Postings using BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install beautifulsoup4\n",
    "# !pip install requests\n",
    "# !pip install pandas\n",
    "\n",
    "# !pip install selenium\n",
    "# !pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import requests \n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup \n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input Search URL and get HTML\n",
    "- Use selenium to load the page because the webpage loads the data dynamically (i.e. the full HTML will not be returned by using BeautifulSoup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_37900\\1546945219.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path = \"C:/Users/user/chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "# chromedriver_path = \"C:/Users/user/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(executable_path = \"C:/Users/user/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pages = 247\n",
    "\n",
    "# Initialise list to store details of each individual job listing post\n",
    "metadata = []\n",
    "\n",
    "# Iterate through all pages\n",
    "for page_num in range(1, num_pages+1):\n",
    "    url = f\"https://www.nodeflair.com/jobs?query=cloud&page={page_num}&sort_by=recent#\"\n",
    "    driver.get(url) \n",
    "    time.sleep(3)\n",
    "\n",
    "    # Get Soup using BeautifulSoup after loading complete HTML\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "    # Find all job posting cards\n",
    "    job_listings = soup.find_all(\"div\", class_=\"col-12 col-sm-12 col-md-6 col-lg-4\")\n",
    "    \n",
    "    # Iterate through all (12) job listings on a page to get link to individual listing and date posted\n",
    "    for listing in job_listings:\n",
    "        job_url = listing.find(\"a\").get(\"href\")\n",
    "        date = listing.find(\"p\", {\"style\": \"font-style: italic; color: rgb(131, 131, 131);\"}).get_text()\n",
    "\n",
    "        metadata.append([job_url, date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Date posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/jobs/53907</td>\n",
       "      <td>about 11 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/jobs/53898</td>\n",
       "      <td>about 11 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/jobs/53894</td>\n",
       "      <td>about 11 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/jobs/53893</td>\n",
       "      <td>about 11 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/jobs/53891</td>\n",
       "      <td>about 11 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>/jobs/46008</td>\n",
       "      <td>about 2 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>/jobs/46001</td>\n",
       "      <td>about 2 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>/jobs/45989</td>\n",
       "      <td>about 2 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>/jobs/45982</td>\n",
       "      <td>about 2 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963</th>\n",
       "      <td>/jobs/45978</td>\n",
       "      <td>about 2 months ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2964 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              URL         Date posted\n",
       "0     /jobs/53907  about 11 hours ago\n",
       "1     /jobs/53898  about 11 hours ago\n",
       "2     /jobs/53894  about 11 hours ago\n",
       "3     /jobs/53893  about 11 hours ago\n",
       "4     /jobs/53891  about 11 hours ago\n",
       "...           ...                 ...\n",
       "2959  /jobs/46008  about 2 months ago\n",
       "2960  /jobs/46001  about 2 months ago\n",
       "2961  /jobs/45989  about 2 months ago\n",
       "2962  /jobs/45982  about 2 months ago\n",
       "2963  /jobs/45978  about 2 months ago\n",
       "\n",
       "[2964 rows x 2 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert each job posting to a row in a DataFrame\n",
    "job_listings_df = pd.DataFrame(data = metadata, columns=[\"URL\", \"Date posted\"])\n",
    "job_listings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_listings_df.to_csv(\"nodeflair_links.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to get data from each job posting\n",
    "- Job Title ✔\n",
    "- Company ✔\n",
    "- Salary ✔\n",
    "- Job Type ✔\n",
    "- Seniority ✔\n",
    "- Years of Experience ✔\n",
    "- Tech Stack ✔\n",
    "- Job Description ✔\n",
    "  - Click Read More "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJobTitle(soup):\n",
    "    job_title = soup.find(\"h1\", class_=\"job-title-name\").get_text()\n",
    "    return job_title\n",
    "\n",
    "def getCompanyName(soup):\n",
    "    company_name = soup.find(\"h2\", class_=\"company-title-name\").get_text()\n",
    "    return company_name\n",
    "\n",
    "def getSeniorityTechStacks(soup):\n",
    "    # Both Seniority and Tech Stack have the same HTML class \n",
    "    tags = [tag.get_text() for tag in soup.find_all(\"div\", class_=\"grey-tag\")]\n",
    "    cleaned_tags = [tag.replace(\"\\n\", \"\").replace(\" \", \"\") for tag in tags]\n",
    "\n",
    "    seniority_tags = [\"Mid\", \"Senior\", \"Lead\", \"Manager\", \"Director\", \"Principal\", \"Intern\", \"Junior\"]\n",
    "    seniority = []\n",
    "    tech_stack = []\n",
    "\n",
    "    # Differentiating between tags for Seniority and Tech Stack\n",
    "    for tag in cleaned_tags:\n",
    "        if tag in seniority_tags:\n",
    "            seniority.append(tag)\n",
    "        else:\n",
    "            tech_stack.append(tag)\n",
    "\n",
    "    return seniority, tech_stack\n",
    "\n",
    "def getSalaryJobTypeYears(soup):\n",
    "    # Salary, Job Type, Years of Experience do not have classes tagged to them \n",
    "    # Some information can be missing. Find if the headers exist first\n",
    "    all_b = soup.find_all(\"b\")\n",
    "\n",
    "    # Can only be identified by text between <br> tags\n",
    "    all_br = soup.find_all(\"br\")\n",
    "\n",
    "    required_headers = [\"Salary\", \"Job Type\", \"Years of Experience\"]\n",
    "    headers = []\n",
    "    for header in all_b:\n",
    "        text = header.get_text()\n",
    "        if text in required_headers:\n",
    "            headers.append(text)\n",
    "\n",
    "    output = []\n",
    "    for b in all_br:\n",
    "        # Content after the <br> tag\n",
    "        next_s = b.nextSibling\n",
    "\n",
    "        if str(type(next_s)) == '<class \\'bs4.element.NavigableString\\'>':\n",
    "            text = next_s.get_text()\n",
    "            if text != \"\\n\":\n",
    "                output.append(text.strip())\n",
    "\n",
    "    salary = '-'\n",
    "    job_type = '-'\n",
    "    years_of_experience = '-'\n",
    "\n",
    "    for i in range(len(headers)):\n",
    "        if headers[i] == \"Salary\":\n",
    "            salary = output[i]\n",
    "        elif headers[i] == \"Job Type\":\n",
    "            job_type = output[i]\n",
    "        elif headers[i] == \"Years of Experience\":\n",
    "            years_of_experience = output[i]\n",
    "    \n",
    "    return salary, job_type, years_of_experience\n",
    "\n",
    "\n",
    "def getJobDesc(soup):\n",
    "    job_description_container = soup.find(\"div\", id=\"job-description\")\n",
    "\n",
    "    text_list = []\n",
    "    for text in job_description_container.find_all(\"div\"):\n",
    "        text = text.get_text()\n",
    "        if text != \"\":\n",
    "            text_list.append(text)\n",
    "\n",
    "    for text in job_description_container.find_all(\"ul\"):\n",
    "        points = text.find_all(\"li\")\n",
    "        for point in points:\n",
    "            if point != \"\":\n",
    "                text_list.append(point.get_text())\n",
    "\n",
    "    return \" \".join(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(soup):\n",
    "    job_title = getJobTitle(soup)\n",
    "    company_name = getCompanyName(soup)\n",
    "    seniority, techstack = getSeniorityTechStacks(soup)\n",
    "    salary, job_type, years_of_experience = getSalaryJobTypeYears(soup)\n",
    "    \n",
    "\n",
    "    job_desc = getJobDesc(soup)\n",
    "\n",
    "    data = [job_title, company_name, seniority, salary, job_type, years_of_experience, techstack, job_desc]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapePost(job_url):\n",
    "    print(\"scraping:\", job_url)\n",
    "\n",
    "    try: \n",
    "        new_url = f\"https://www.nodeflair.com/{job_url}\"\n",
    "        driver.get(new_url) \n",
    "\n",
    "        # Manually expand the size of the container to display all text\n",
    "        expand_text_toggle = driver.execute_script(\"document.getElementById('job-description').style.height = '1000px';\")\n",
    "\n",
    "        # Manually display all hidden text \n",
    "        read_more_toggle = driver.execute_script(\"document.getElementById('job-description').getAttribute('aria-expanded').innerHTML = 'true';\")\n",
    "        time.sleep(3)\n",
    "    \n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "        data = getData(soup)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "        data = getData(soup)\n",
    "        \n",
    "    print(\" done scraping\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatePosted(text):\n",
    "    date_of_scraping = datetime.now()\n",
    "    date_posted = ''\n",
    "\n",
    "    if \"hours\" in text:\n",
    "        date = date_of_scraping + timedelta(days=-1)\n",
    "        date_posted = date.date().strftime('%y-%m-%d')\n",
    "        \n",
    "    elif \"months\" in text:\n",
    "        n_months = text.split(\" \")[1]\n",
    "        date = date_of_scraping + timedelta(months=-n_months)\n",
    "        date_posted = date.date().strftime('%y-%m-%d')\n",
    "\n",
    "    return date_posted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Date posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/jobs/53907</td>\n",
       "      <td>about 11 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/jobs/53898</td>\n",
       "      <td>about 11 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/jobs/53894</td>\n",
       "      <td>about 11 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/jobs/53893</td>\n",
       "      <td>about 11 hours ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/jobs/53891</td>\n",
       "      <td>about 11 hours ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           URL         Date posted\n",
       "0  /jobs/53907  about 11 hours ago\n",
       "1  /jobs/53898  about 11 hours ago\n",
       "2  /jobs/53894  about 11 hours ago\n",
       "3  /jobs/53893  about 11 hours ago\n",
       "4  /jobs/53891  about 11 hours ago"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_listings_df = pd.read_csv(\"../data/nodeflair/nodeflair_links.csv\", index_col=0)\n",
    "job_listings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_df(df):\n",
    "    df[\"Job Title\"] = df[\"data\"].apply(lambda x: x[0])\n",
    "    df[\"Company Name\"] = df[\"data\"].apply(lambda x: x[1])\n",
    "    df[\"Seniority\"] = df[\"data\"].apply(lambda x: x[2])\n",
    "    df[\"Salary\"] = df[\"data\"].apply(lambda x: x[3])\n",
    "    df[\"Job Type\"] = df[\"data\"].apply(lambda x: x[4])\n",
    "    df[\"Years of Experience\"] = df[\"data\"].apply(lambda x: x[5])\n",
    "    df[\"Tech Stack\"] = df[\"data\"].apply(lambda x: x[6])\n",
    "    df[\"Job Desc\"] = df[\"data\"].apply(lambda x: x[7])\n",
    "    # job_listings_df[\"Date posted\"] = job_listings_df[\"Date posted\"].apply(getDatePosted)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping: /jobs/53907\n",
      " done scraping\n",
      "scraping: /jobs/53898\n",
      " done scraping\n",
      "scraping: /jobs/53894\n",
      " done scraping\n",
      "scraping: /jobs/53893\n",
      " done scraping\n",
      "scraping: /jobs/53891\n",
      " done scraping\n",
      "scraping: /jobs/53885\n",
      " done scraping\n",
      "scraping: /jobs/53879\n",
      " done scraping\n",
      "scraping: /jobs/53876\n",
      " done scraping\n",
      "scraping: /jobs/53870\n",
      " done scraping\n",
      "scraping: /jobs/53869\n",
      " done scraping\n",
      "scraping: /jobs/53862\n",
      " done scraping\n",
      "scraping: /jobs/53861\n",
      " done scraping\n",
      "scraping: /jobs/53860\n",
      " done scraping\n",
      "scraping: /jobs/53856\n",
      " done scraping\n",
      "scraping: /jobs/53852\n",
      " done scraping\n",
      "scraping: /jobs/53849\n",
      " done scraping\n",
      "scraping: /jobs/53847\n",
      " done scraping\n",
      "scraping: /jobs/53845\n",
      " done scraping\n",
      "scraping: /jobs/53842\n",
      " done scraping\n",
      "scraping: /jobs/53839\n",
      " done scraping\n",
      "scraping: /jobs/53838\n",
      " done scraping\n",
      "scraping: /jobs/53837\n",
      " done scraping\n",
      "scraping: /jobs/53836\n",
      " done scraping\n",
      "scraping: /jobs/53835\n",
      " done scraping\n",
      "scraping: /jobs/53833\n",
      " done scraping\n",
      "scraping: /jobs/53832\n",
      " done scraping\n",
      "scraping: /jobs/53830\n",
      " done scraping\n",
      "scraping: /jobs/53827\n",
      " done scraping\n",
      "scraping: /jobs/53824\n",
      " done scraping\n",
      "scraping: /jobs/53822\n",
      " done scraping\n",
      "scraping: /jobs/53821\n",
      " done scraping\n",
      "scraping: /jobs/53819\n",
      " done scraping\n",
      "scraping: /jobs/53815\n",
      " done scraping\n",
      "scraping: /jobs/53809\n",
      " done scraping\n",
      "scraping: /jobs/53797\n",
      " done scraping\n",
      "scraping: /jobs/53793\n",
      " done scraping\n",
      "scraping: /jobs/53790\n",
      " done scraping\n",
      "scraping: /jobs/53788\n",
      " done scraping\n",
      "scraping: /jobs/53787\n",
      " done scraping\n",
      "scraping: /jobs/53784\n",
      " done scraping\n",
      "scraping: /jobs/53782\n",
      " done scraping\n",
      "scraping: /jobs/53781\n",
      " done scraping\n",
      "scraping: /jobs/53777\n",
      "Message: javascript error: Cannot set properties of null (setting 'innerHTML')\n",
      "  (Session info: chrome=99.0.4844.51)\n",
      "Stacktrace:\n",
      "Backtrace:\n",
      "\tOrdinal0 [0x00E79943+2595139]\n",
      "\tOrdinal0 [0x00E0C9F1+2148849]\n",
      "\tOrdinal0 [0x00D04528+1066280]\n",
      "\tOrdinal0 [0x00D06E04+1076740]\n",
      "\tOrdinal0 [0x00D06CBE+1076414]\n",
      "\tOrdinal0 [0x00D0763A+1078842]\n",
      "\tOrdinal0 [0x00D5C529+1426729]\n",
      "\tOrdinal0 [0x00D4B9EC+1358316]\n",
      "\tOrdinal0 [0x00D5BAF2+1424114]\n",
      "\tOrdinal0 [0x00D4B806+1357830]\n",
      "\tOrdinal0 [0x00D26086+1204358]\n",
      "\tOrdinal0 [0x00D26F96+1208214]\n",
      "\tGetHandleVerifier [0x0101B232+1658114]\n",
      "\tGetHandleVerifier [0x010D312C+2411516]\n",
      "\tGetHandleVerifier [0x00F0F261+560433]\n",
      "\tGetHandleVerifier [0x00F0E366+556598]\n",
      "\tOrdinal0 [0x00E1286B+2173035]\n",
      "\tOrdinal0 [0x00E175F8+2192888]\n",
      "\tOrdinal0 [0x00E176E5+2193125]\n",
      "\tOrdinal0 [0x00E211FC+2232828]\n",
      "\tBaseThreadInitThunk [0x75FE6359+25]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x772A8944+228]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x772A8914+180]\n",
      "\n",
      " done scraping\n",
      "scraping: /jobs/53774\n",
      " done scraping\n",
      "scraping: /jobs/53768\n",
      " done scraping\n",
      "scraping: /jobs/53765\n",
      " done scraping\n",
      "scraping: /jobs/53759\n",
      " done scraping\n",
      "scraping: /jobs/53757\n",
      " done scraping\n",
      "scraping: /jobs/53754\n",
      " done scraping\n",
      "scraping: /jobs/53752\n",
      " done scraping\n",
      "scraping: /jobs/53745\n",
      " done scraping\n",
      "scraping: /jobs/53741\n",
      " done scraping\n",
      "scraping: /jobs/53740\n",
      " done scraping\n",
      "scraping: /jobs/53739\n",
      " done scraping\n",
      "scraping: /jobs/53734\n",
      " done scraping\n",
      "scraping: /jobs/53732\n",
      " done scraping\n",
      "scraping: /jobs/53731\n",
      " done scraping\n",
      "scraping: /jobs/53730\n",
      " done scraping\n",
      "scraping: /jobs/53729\n",
      " done scraping\n",
      "scraping: /jobs/53725\n",
      " done scraping\n",
      "scraping: /jobs/53724\n",
      " done scraping\n",
      "scraping: /jobs/53722\n",
      " done scraping\n",
      "scraping: /jobs/53719\n",
      " done scraping\n",
      "scraping: /jobs/53718\n",
      " done scraping\n",
      "scraping: /jobs/53715\n",
      " done scraping\n",
      "scraping: /jobs/53714\n",
      " done scraping\n",
      "scraping: /jobs/53712\n",
      " done scraping\n",
      "scraping: /jobs/53711\n",
      " done scraping\n",
      "scraping: /jobs/53708\n",
      " done scraping\n",
      "scraping: /jobs/53703\n",
      " done scraping\n",
      "scraping: /jobs/53700\n",
      " done scraping\n",
      "scraping: /jobs/53694\n",
      " done scraping\n",
      "scraping: /jobs/53690\n",
      " done scraping\n",
      "scraping: /jobs/53677\n",
      " done scraping\n",
      "scraping: /jobs/53676\n",
      " done scraping\n",
      "scraping: /jobs/53674\n",
      " done scraping\n",
      "scraping: /jobs/53668\n",
      " done scraping\n",
      "scraping: /jobs/53664\n",
      " done scraping\n",
      "scraping: /jobs/53661\n",
      " done scraping\n",
      "scraping: /jobs/53657\n",
      " done scraping\n",
      "scraping: /jobs/53656\n",
      " done scraping\n",
      "scraping: /jobs/53654\n",
      " done scraping\n",
      "scraping: /jobs/53652\n",
      " done scraping\n",
      "scraping: /jobs/53649\n",
      " done scraping\n",
      "scraping: /jobs/53646\n",
      " done scraping\n",
      "scraping: /jobs/53645\n",
      " done scraping\n",
      "scraping: /jobs/53644\n",
      " done scraping\n",
      "scraping: /jobs/53643\n",
      " done scraping\n",
      "scraping: /jobs/53642\n",
      " done scraping\n",
      "scraping: /jobs/53638\n",
      " done scraping\n",
      "scraping: /jobs/53636\n",
      " done scraping\n",
      "scraping: /jobs/53635\n",
      " done scraping\n",
      "scraping: /jobs/53632\n",
      " done scraping\n",
      "scraping: /jobs/53630\n",
      " done scraping\n",
      "scraping: /jobs/53629\n",
      " done scraping\n",
      "scraping: /jobs/53627\n",
      " done scraping\n",
      "scraping: /jobs/53626\n",
      " done scraping\n",
      "scraping: /jobs/53618\n",
      " done scraping\n",
      "scraping: /jobs/53617\n",
      " done scraping\n",
      "scraping: /jobs/53616\n",
      " done scraping\n",
      "scraping: /jobs/53615\n",
      " done scraping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_37900\\3604307494.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  job_listings_df[\"data\"] = job_listings_df[\"URL\"].apply(scrapePost)\n"
     ]
    }
   ],
   "source": [
    "print(\"Date of scraping:\", datetime.now())\n",
    "output_df = pd.DataFrame()\n",
    "start = 0\n",
    "end = 100\n",
    "\n",
    "while end <= len(job_listings_df):\n",
    "    try:\n",
    "        driver = webdriver.Chrome(executable_path = \"C:/Users/user/chromedriver.exe\")\n",
    "        job_listings_df_100 = job_listings_df[start:end+1]\n",
    "        job_listings_df_100[\"data\"] = job_listings_df_100[\"URL\"].apply(scrapePost)\n",
    "        print(f\"{end} done\")\n",
    "        \n",
    "        output_df = pd.concat([output_df, format_df(job_listings_df_100)])\n",
    "        start = end+1\n",
    "        end += 100\n",
    "\n",
    "    except:\n",
    "        driver = webdriver.Chrome(executable_path = \"C:/Users/user/chromedriver.exe\")\n",
    "        job_listings_df_100 = job_listings_df[start:end+1]\n",
    "        job_listings_df_100[\"data\"] = job_listings_df_100[\"URL\"].apply(scrapePost)\n",
    "        print(f\"{end} done\")\n",
    "        \n",
    "        output_df = pd.concat([output_df, format_df(job_listings_df_100)])\n",
    "        start = end+1\n",
    "        end += 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Date posted</th>\n",
       "      <th>data</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Seniority</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Years of Experience</th>\n",
       "      <th>Tech Stack</th>\n",
       "      <th>Job Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/jobs/53907</td>\n",
       "      <td>about 11 hours ago</td>\n",
       "      <td>[ReactJS Developer (Full Stack), Apar Technolo...</td>\n",
       "      <td>ReactJS Developer (Full Stack)</td>\n",
       "      <td>Apar Technologies</td>\n",
       "      <td>[Mid, Junior]</td>\n",
       "      <td>$6,419 - $8,819 SGD / Monthly</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>2-3 years</td>\n",
       "      <td>[Docker, CloudFoundry, Spring, SonarQube, TDD,...</td>\n",
       "      <td>We are looking for a candidate to fill in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/jobs/53898</td>\n",
       "      <td>about 11 hours ago</td>\n",
       "      <td>[Manager, SRE, Rakuten Viki, [Manager], -, Per...</td>\n",
       "      <td>Manager, SRE</td>\n",
       "      <td>Rakuten Viki</td>\n",
       "      <td>[Manager]</td>\n",
       "      <td>-</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>Information not provided</td>\n",
       "      <td>[Docker, API, PagerDuty, GKE, ELK, Sprint, UNI...</td>\n",
       "      <td>The SRE team at Viki is responsible for buildi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/jobs/53894</td>\n",
       "      <td>about 11 hours ago</td>\n",
       "      <td>[DevOps Engineer, GovTech, [Junior], $5,800 - ...</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>GovTech</td>\n",
       "      <td>[Junior]</td>\n",
       "      <td>$5,800 - $9,600 SGD / Monthly</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>At least 2 years</td>\n",
       "      <td>[Docker, DockerCompose, Fluentd, Clair, Packer...</td>\n",
       "      <td>Our team in GovTech works on highly impactful ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/jobs/53893</td>\n",
       "      <td>about 11 hours ago</td>\n",
       "      <td>[VP, System Analyst, United Overseas Bank Limi...</td>\n",
       "      <td>VP, System Analyst</td>\n",
       "      <td>United Overseas Bank Limited (UOB)</td>\n",
       "      <td>[Senior]</td>\n",
       "      <td>-</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>10-15 years</td>\n",
       "      <td>[ETL, Oracle, Experian, Strategy, Teradata, Ql...</td>\n",
       "      <td>The Technology and Operations function is comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/jobs/53891</td>\n",
       "      <td>about 11 hours ago</td>\n",
       "      <td>[DevOps &amp; Lab Manager (SG - Edge), Dell Techno...</td>\n",
       "      <td>DevOps &amp; Lab Manager (SG - Edge)</td>\n",
       "      <td>Dell Technologies</td>\n",
       "      <td>[Manager]</td>\n",
       "      <td>$11,000 - $22,000 SGD / Monthly</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>At least 12 years</td>\n",
       "      <td>[Docker, Strategy, Container, Microsoft, CI, N...</td>\n",
       "      <td>Dell Technologies is seeking an entrepreneuria...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>/jobs/46156</td>\n",
       "      <td>about 2 months ago</td>\n",
       "      <td>[DevOps Engineer, 2C2P, [Mid], $7,000 - $10,00...</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>2C2P</td>\n",
       "      <td>[Mid]</td>\n",
       "      <td>$7,000 - $10,000 SGD / Monthly</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>At least 3 years</td>\n",
       "      <td>[GitLab, HTTP, UDP, TCP, ShellScript, GitLabCI...</td>\n",
       "      <td>2C2P is looking for a .NET DevOps Engineer to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>/jobs/46153</td>\n",
       "      <td>about 2 months ago</td>\n",
       "      <td>[DevOps Engineer, FINXFLO, [], -, Permanent, I...</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>FINXFLO</td>\n",
       "      <td>[]</td>\n",
       "      <td>-</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>Information not provided</td>\n",
       "      <td>[Strategy, ShellScript, CI, Shell, UNIX, JavaS...</td>\n",
       "      <td>Alpha Stone Capital is looking for an amazing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>/jobs/46151</td>\n",
       "      <td>about 2 months ago</td>\n",
       "      <td>[DevOps Engineer, Quilt.AI, [Mid], -, Permanen...</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Quilt.AI</td>\n",
       "      <td>[Mid]</td>\n",
       "      <td>-</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>At least 3 years</td>\n",
       "      <td>[Next.js, Docker, Cloudflare, DockerSwarm, Str...</td>\n",
       "      <td>As part of a growing team consisting of ML exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>/jobs/46149</td>\n",
       "      <td>about 2 months ago</td>\n",
       "      <td>[Software Engineer, Zoku Integrated Commerce, ...</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>Zoku Integrated Commerce</td>\n",
       "      <td>[Mid]</td>\n",
       "      <td>-</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>At least 3 years</td>\n",
       "      <td>[API, Magento, CI, DOM, Node.js, NoSQL, JavaSc...</td>\n",
       "      <td>We are hiring software engineers with expertis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>/jobs/46147</td>\n",
       "      <td>about 2 months ago</td>\n",
       "      <td>[Sr. Site Reliability Engineer - Hadoop, Xiaom...</td>\n",
       "      <td>Sr. Site Reliability Engineer - Hadoop</td>\n",
       "      <td>Xiaomi Technology</td>\n",
       "      <td>[Senior]</td>\n",
       "      <td>-</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>Information not provided</td>\n",
       "      <td>[MapReduce, API, Container, JMX, Analytics, Zo...</td>\n",
       "      <td>Job Requirement： Deploy, operate, maintain, se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2901 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              URL         Date posted  \\\n",
       "0     /jobs/53907  about 11 hours ago   \n",
       "1     /jobs/53898  about 11 hours ago   \n",
       "2     /jobs/53894  about 11 hours ago   \n",
       "3     /jobs/53893  about 11 hours ago   \n",
       "4     /jobs/53891  about 11 hours ago   \n",
       "...           ...                 ...   \n",
       "2896  /jobs/46156  about 2 months ago   \n",
       "2897  /jobs/46153  about 2 months ago   \n",
       "2898  /jobs/46151  about 2 months ago   \n",
       "2899  /jobs/46149  about 2 months ago   \n",
       "2900  /jobs/46147  about 2 months ago   \n",
       "\n",
       "                                                   data  \\\n",
       "0     [ReactJS Developer (Full Stack), Apar Technolo...   \n",
       "1     [Manager, SRE, Rakuten Viki, [Manager], -, Per...   \n",
       "2     [DevOps Engineer, GovTech, [Junior], $5,800 - ...   \n",
       "3     [VP, System Analyst, United Overseas Bank Limi...   \n",
       "4     [DevOps & Lab Manager (SG - Edge), Dell Techno...   \n",
       "...                                                 ...   \n",
       "2896  [DevOps Engineer, 2C2P, [Mid], $7,000 - $10,00...   \n",
       "2897  [DevOps Engineer, FINXFLO, [], -, Permanent, I...   \n",
       "2898  [DevOps Engineer, Quilt.AI, [Mid], -, Permanen...   \n",
       "2899  [Software Engineer, Zoku Integrated Commerce, ...   \n",
       "2900  [Sr. Site Reliability Engineer - Hadoop, Xiaom...   \n",
       "\n",
       "                                   Job Title  \\\n",
       "0             ReactJS Developer (Full Stack)   \n",
       "1                               Manager, SRE   \n",
       "2                            DevOps Engineer   \n",
       "3                         VP, System Analyst   \n",
       "4           DevOps & Lab Manager (SG - Edge)   \n",
       "...                                      ...   \n",
       "2896                         DevOps Engineer   \n",
       "2897                         DevOps Engineer   \n",
       "2898                         DevOps Engineer   \n",
       "2899                       Software Engineer   \n",
       "2900  Sr. Site Reliability Engineer - Hadoop   \n",
       "\n",
       "                            Company Name      Seniority  \\\n",
       "0                      Apar Technologies  [Mid, Junior]   \n",
       "1                           Rakuten Viki      [Manager]   \n",
       "2                                GovTech       [Junior]   \n",
       "3     United Overseas Bank Limited (UOB)       [Senior]   \n",
       "4                      Dell Technologies      [Manager]   \n",
       "...                                  ...            ...   \n",
       "2896                                2C2P          [Mid]   \n",
       "2897                             FINXFLO             []   \n",
       "2898                            Quilt.AI          [Mid]   \n",
       "2899            Zoku Integrated Commerce          [Mid]   \n",
       "2900                   Xiaomi Technology       [Senior]   \n",
       "\n",
       "                               Salary   Job Type       Years of Experience  \\\n",
       "0       $6,419 - $8,819 SGD / Monthly  Permanent                 2-3 years   \n",
       "1                                   -  Permanent  Information not provided   \n",
       "2       $5,800 - $9,600 SGD / Monthly  Permanent          At least 2 years   \n",
       "3                                   -  Permanent               10-15 years   \n",
       "4     $11,000 - $22,000 SGD / Monthly  Permanent         At least 12 years   \n",
       "...                               ...        ...                       ...   \n",
       "2896   $7,000 - $10,000 SGD / Monthly  Permanent          At least 3 years   \n",
       "2897                                -  Permanent  Information not provided   \n",
       "2898                                -  Permanent          At least 3 years   \n",
       "2899                                -  Permanent          At least 3 years   \n",
       "2900                                -  Permanent  Information not provided   \n",
       "\n",
       "                                             Tech Stack  \\\n",
       "0     [Docker, CloudFoundry, Spring, SonarQube, TDD,...   \n",
       "1     [Docker, API, PagerDuty, GKE, ELK, Sprint, UNI...   \n",
       "2     [Docker, DockerCompose, Fluentd, Clair, Packer...   \n",
       "3     [ETL, Oracle, Experian, Strategy, Teradata, Ql...   \n",
       "4     [Docker, Strategy, Container, Microsoft, CI, N...   \n",
       "...                                                 ...   \n",
       "2896  [GitLab, HTTP, UDP, TCP, ShellScript, GitLabCI...   \n",
       "2897  [Strategy, ShellScript, CI, Shell, UNIX, JavaS...   \n",
       "2898  [Next.js, Docker, Cloudflare, DockerSwarm, Str...   \n",
       "2899  [API, Magento, CI, DOM, Node.js, NoSQL, JavaSc...   \n",
       "2900  [MapReduce, API, Container, JMX, Analytics, Zo...   \n",
       "\n",
       "                                               Job Desc  \n",
       "0     We are looking for a candidate to fill in the ...  \n",
       "1     The SRE team at Viki is responsible for buildi...  \n",
       "2     Our team in GovTech works on highly impactful ...  \n",
       "3     The Technology and Operations function is comp...  \n",
       "4     Dell Technologies is seeking an entrepreneuria...  \n",
       "...                                                 ...  \n",
       "2896  2C2P is looking for a .NET DevOps Engineer to ...  \n",
       "2897  Alpha Stone Capital is looking for an amazing ...  \n",
       "2898  As part of a growing team consisting of ML exp...  \n",
       "2899  We are hiring software engineers with expertis...  \n",
       "2900  Job Requirement： Deploy, operate, maintain, se...  \n",
       "\n",
       "[2901 rows x 11 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv(\"nodeflair_jobpostings.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38d51dd8e8d25c2b4859ddf5fde4d8615b38902fd48d30a19bf46ddb81d406a6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
