{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28352659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "pd.set_option('display.max_colwidth', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a37dcc",
   "metadata": {},
   "source": [
    "# Get Links\n",
    "To Do: \n",
    "1. Create a csv file named \"Links_MonsterSg\" in your folder\n",
    "2. In the csv file, add in the following headers: \n",
    "    - job_title\n",
    "    - company\n",
    "    - url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7416539",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_url = \"https://www.monster.com.sg/srp/results?query=%22Cloud%20Computing%22&locations=Singapore&searchId=89523e9b-a41c-4c28-ae41-fa370f6a9ac4\"\n",
    "\n",
    "all_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3363bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=Service(\"C:/chrome/chromedriver.exe\"))\n",
    "\n",
    "\n",
    "driver.get(search_url)\n",
    "\n",
    "result_text = driver.find_element(By.XPATH, '//*[@id=\"srp-main-container\"]/div[1]/div[1]/span').text\n",
    "result_num = result_text.split()[-1]\n",
    "max_page = int(result_num) // 25\n",
    "# max_page = 2\n",
    "        \n",
    "count = 0\n",
    "\n",
    "while count < max_page: \n",
    "    \n",
    "    driver.get(search_url)\n",
    "    \n",
    "    # scroll to bottom of page\n",
    "    y = 0\n",
    "    for timer in range(60):\n",
    "        driver.execute_script(\"window.scrollTo(0, \"+str(y)+\")\")\n",
    "        y += 100  \n",
    "        time.sleep(0.5)    \n",
    "    \n",
    "    next_button = driver.find_element(By.XPATH, \"/html/body/div[2]/div[1]/div[5]/div[2]/div[2]/div/div[1]/div/div/div[4]/div/div/div[2]/a[2]/button\")\n",
    "    ActionChains(driver).move_to_element(next_button)\n",
    "\n",
    "    wait = WebDriverWait(driver, 20)\n",
    "    wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"medium\")))\n",
    "    \n",
    "    # If subscribe modal pops up\n",
    "    driver.switch_to.active_element\n",
    "    \n",
    "    try: \n",
    "        driver.find_element(By.ID, \"wzrk-cancel\").click()\n",
    "        driver.switch_to.active_element\n",
    "        \n",
    "    except: \n",
    "        pass \n",
    "\n",
    "    # get data\n",
    "    details_dict = { 'job title': [], 'company' : [], 'url': []}\n",
    "\n",
    "    # job title & url\n",
    "    try: \n",
    "        title_element = driver.find_elements(By.CLASS_NAME, \"medium\")\n",
    "        for i in range(len(title_element)):\n",
    "            if title_element[i].text != \"\":\n",
    "                details_dict['job title'].append(title_element[i].text)\n",
    "\n",
    "            url_element = title_element[i].find_elements(By.TAG_NAME, \"a\")\n",
    "            for j in range(len(url_element)):\n",
    "                url = url_element[0].get_attribute(\"href\")\n",
    "                details_dict['url'].append(url)\n",
    "                break\n",
    "    except:\n",
    "        print(\"*** error: job title & url ***\")\n",
    "\n",
    "    # company name \n",
    "    try:\n",
    "        company_element = driver.find_elements(By.CLASS_NAME, \"company-name\")\n",
    "        for i in range(len(company_element)):\n",
    "            details_dict['company'].append(company_element[i].text)\n",
    "    except:\n",
    "        print(\"*** error: company name *** \")\n",
    "\n",
    "    df = pd.DataFrame(details_dict)\n",
    "    \n",
    "    all_df = all_df.append(df, ignore_index=True)\n",
    "    \n",
    "    print(f'page {count+1} done') \n",
    "    \n",
    "    if count % 10 == 0:    \n",
    "        all_df.to_csv('./Links_MonsterSg.csv', mode='a', index=False, header=False)                                 \n",
    "        all_df = pd.DataFrame()\n",
    "    \n",
    "    # Click next   \n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[2]/div[1]/div[5]/div[2]/div[2]/div/div[1]/div/div/div[4]/div/div/div[2]/a[2]/button\")))  \n",
    "    next_button.click()\n",
    "    \n",
    "    search_url = driver.current_url\n",
    "    print(search_url)\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "all_df.to_csv('./Links_MonsterSg.csv', mode='a', index=False, header=False)                            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6623ac",
   "metadata": {},
   "source": [
    "### Drop Duplicates\n",
    "Companies may repost the same job posting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c05944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_df = pd.read_csv('./Cloud_All Links_MonsterSg.csv')\n",
    "links_df.drop_duplicates(inplace=True)\n",
    "links_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76fa0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_df.to_csv('Cloud_Links_MonsterSg.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8bced5",
   "metadata": {},
   "source": [
    "# Get Post\n",
    "To Do: \n",
    "1. Create a csv file named \"Posts_MonsterSg\" in your folder\n",
    "2. In the csv file, add in the following headers: \n",
    "    'job_title', 'company', 'salary', 'job_type', 'years_experience', 'tech_stack', \n",
    "    'job_description', 'industry', 'function', 'roles', 'last_updated', 'posted_on'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7588851a",
   "metadata": {},
   "source": [
    "#### Function to get data from each job posting\n",
    "- Job Title ✔\n",
    "- Company ✔\n",
    "- Salary ✔\n",
    "- Job Type ✔\n",
    "- Seniority ??\n",
    "- Years of Experience ✔\n",
    "- Tech Stack ✔\n",
    "- Job Description ✔\n",
    "- Industry ✔\n",
    "- Function ✔\n",
    "- Roles ✔\n",
    "- Last updated ✔\n",
    "- Posted on ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc71f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update directory\n",
    "links_df = pd.read_csv('./Cloud_Links_MonsterSg.csv')\n",
    "links_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cb611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove search id in url\n",
    "\n",
    "def clean_url(full_url):\n",
    "    return (full_url.split('&searchId')[0])\n",
    "\n",
    "links_df['cleaned_url'] = links_df['url'].apply(lambda x: clean_url(x))\n",
    "links_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271dcf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details(index, post_url, driver):\n",
    "\n",
    "    driver.get(post_url)\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "\n",
    "    # If subscribe modal pops up\n",
    "    driver.switch_to.active_element\n",
    "\n",
    "    try: \n",
    "        driver.find_element(By.ID, \"wzrk-cancel\").click()\n",
    "        driver.switch_to.active_element\n",
    "\n",
    "    except: \n",
    "        pass \n",
    "\n",
    "\n",
    "    # Salary\n",
    "    salary = \"\"\n",
    "    try: \n",
    "        wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'package')))\n",
    "        salary = driver.find_element(By.CLASS_NAME, 'package').text\n",
    "    except: \n",
    "        print(f'*** Error: {index} \\n  package \\n {post_url}')\n",
    "\n",
    "    # Job Type\n",
    "    job_type = \"\"\n",
    "    try: \n",
    "        wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'color-grey-light')))\n",
    "        job_type = driver.find_element(By.CLASS_NAME,'color-grey-light').text\n",
    "    except: \n",
    "        print(f'*** Error: {index} \\n  job type  \\n {post_url}')\n",
    "\n",
    "    # Years of Experience\n",
    "    exp = \"\"\n",
    "    try: \n",
    "        wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'exp')))\n",
    "        exp = driver.find_element(By.CLASS_NAME,'exp').text\n",
    "    except: \n",
    "        print(f'*** Error: {index} \\n  experience \\n {post_url}')\n",
    "\n",
    "    # Tech Stack\n",
    "    tech_stack = \"\"\n",
    "    try:\n",
    "        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '#jobDetailHolder > div > div.job-details-wrapper > div.container.mt20.ui-v3 > div.row.fixed-sb-grid > div.col-md-12.col-lg-9 > div:nth-child(6) > div > div > div > div:nth-child(4) > div.dt-content > p')))\n",
    "        tech_stack = driver.find_element(By.CSS_SELECTOR,'#jobDetailHolder > div > div.job-details-wrapper > div.container.mt20.ui-v3 > div.row.fixed-sb-grid > div.col-md-12.col-lg-9 > div:nth-child(6) > div > div > div > div:nth-child(4) > div.dt-content > p').text\n",
    "    except: \n",
    "        print(f'*** Error: {index} \\n  tech stack \\n {post_url}' )\n",
    "        \n",
    "    # Job Description\n",
    "    job_des = \"\"\n",
    "    try:\n",
    "        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '#jobDetailHolder > div > div.job-details-wrapper > div.container.mt20.ui-v3 > div.row.fixed-sb-grid > div.col-md-12.col-lg-9 > div:nth-child(2) > div > div > div.card-panel.job-description-content > p')))\n",
    "        job_des = driver.find_element(By.CSS_SELECTOR,'#jobDetailHolder > div > div.job-details-wrapper > div.container.mt20.ui-v3 > div.row.fixed-sb-grid > div.col-md-12.col-lg-9 > div:nth-child(2) > div > div > div.card-panel.job-description-content > p').text\n",
    "    except: \n",
    "         print(f'*** Error: {index} \\n  experience \\n {post_url}')\n",
    "            \n",
    "    # Industry\n",
    "    industry = \"\"\n",
    "    try:\n",
    "        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '#jobDetailHolder > div > div.job-details-wrapper > div.container.mt20.ui-v3 > div.row.fixed-sb-grid > div.col-md-12.col-lg-9 > div:nth-child(6) > div > div > div > div:nth-child(1) > div.dt-content > p')))\n",
    "        industry = driver.find_element(By.CSS_SELECTOR, '#jobDetailHolder > div > div.job-details-wrapper > div.container.mt20.ui-v3 > div.row.fixed-sb-grid > div.col-md-12.col-lg-9 > div:nth-child(6) > div > div > div > div:nth-child(1) > div.dt-content > p').text\n",
    "    except: \n",
    "        print(f'*** Error: {index} \\n  industry \\n {post_url}')\n",
    "        \n",
    "    # Function\n",
    "    function = \"\"\n",
    "    try:\n",
    "        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '#jobDetailHolder > div > div.job-details-wrapper > div.container.mt20.ui-v3 > div.row.fixed-sb-grid > div.col-md-12.col-lg-9 > div:nth-child(6) > div > div > div > div:nth-child(2) > div.dt-content > p')))\n",
    "        function = driver.find_element(By.CSS_SELECTOR,'#jobDetailHolder > div > div.job-details-wrapper > div.container.mt20.ui-v3 > div.row.fixed-sb-grid > div.col-md-12.col-lg-9 > div:nth-child(6) > div > div > div > div:nth-child(2) > div.dt-content > p').text\n",
    "    except:  \n",
    "        print(f'*** Error: {index} \\n function \\n {post_url}')\n",
    "        \n",
    "    # Roles\n",
    "    role = \"\"\n",
    "    try:\n",
    "        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '#jobDetailHolder > div > div.job-details-wrapper > div.container.mt20.ui-v3 > div.row.fixed-sb-grid > div.col-md-12.col-lg-9 > div:nth-child(6) > div > div > div > div:nth-child(3) > div.dt-content > p')))\n",
    "        role = driver.find_element(By.CSS_SELECTOR,'#jobDetailHolder > div > div.job-details-wrapper > div.container.mt20.ui-v3 > div.row.fixed-sb-grid > div.col-md-12.col-lg-9 > div:nth-child(6) > div > div > div > div:nth-child(3) > div.dt-content > p').text\n",
    "    except: \n",
    "        print(f'*** Error: {index} \\n role \\n {post_url}')\n",
    "                \n",
    "    # Last Updated        \n",
    "    y = 4000\n",
    "    for timer in range(10):\n",
    "        driver.execute_script(\"window.scrollTo(document.body.scrollHeight, \"+str(y)+\")\")\n",
    "        y -= 200  \n",
    "        time.sleep(1) \n",
    "    \n",
    "    last_updated = \"\"    \n",
    "        \n",
    "    try: \n",
    "        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '#jobDetailHolder > div > div.job-details-wrapper > div.container.mt20.ui-v3 > div.row.fixed-sb-grid > div.col-md-12.col-lg-9 > div.last-updated.fs-14.color-grey.mt20 > span:nth-child(1)')))\n",
    "        last_updated = driver.find_element(By.CSS_SELECTOR,'#jobDetailHolder > div > div.job-details-wrapper > div.container.mt20.ui-v3 > div.row.fixed-sb-grid > div.col-md-12.col-lg-9 > div.last-updated.fs-14.color-grey.mt20 > span:nth-child(1)').text\n",
    "    \n",
    "    except:\n",
    "        print(f'*** Error: {index} \\n last updated \\n {post_url}')\n",
    "        \n",
    "    # Date post\n",
    "    posted_on = \"\"\n",
    "    try:\n",
    "        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '#jobDetailHolder > div > div.job-details-wrapper > div.container.mt20.ui-v3 > div.row.fixed-sb-grid > div.col-md-12.col-lg-9 > div:nth-child(1) > div > div.card-footer.apply-footer.no-bdr.pd0.bg-grey > div.posted-update.pl0 > span:nth-child(1)')))\n",
    "        posted_on = driver.find_element(By.CSS_SELECTOR,'#jobDetailHolder > div > div.job-details-wrapper > div.container.mt20.ui-v3 > div.row.fixed-sb-grid > div.col-md-12.col-lg-9 > div:nth-child(1) > div > div.card-footer.apply-footer.no-bdr.pd0.bg-grey > div.posted-update.pl0 > span:nth-child(1)').text\n",
    "        posted_on = posted_on.split(': ')[1]\n",
    "    except: \n",
    "        print(f'*** Error: {index} \\n  posted on \\n {post_url}')\n",
    "\n",
    "        \n",
    "    return [salary, job_type, exp, tech_stack, job_des, industry, function, role, last_updated, posted_on]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d0068f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(columns = ['job_title', 'company', 'salary', 'job_type', 'years_experience', 'tech_stack', \n",
    "                                 'job_description', 'industry', 'function', 'roles', 'last_updated', 'posted_on'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf16283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Update directory\n",
    "driver = webdriver.Chrome(service=Service(\"C:/chrome/chromedriver.exe\"))\n",
    "\n",
    "\n",
    "# Update start and end index \n",
    "# started: 7881\n",
    "start = 0  \n",
    "end = 2\n",
    "\n",
    "count = 0\n",
    "for i, row in links_df[start : end].iterrows(): \n",
    "    title = [row['job_title']]\n",
    "    company = [row['company']]\n",
    "    url = row['cleaned_url']\n",
    "    details = get_details(i, url, driver)\n",
    "    all_details = title + company + details\n",
    "    \n",
    "        \n",
    "    final_df.loc[count] = all_details\n",
    "    count += 1\n",
    "\n",
    "    \n",
    "    if count % 100 == 0:\n",
    "        print()\n",
    "        print(i, ' Done') \n",
    "        print()\n",
    "        final_df.to_csv('./Posts_MonsterSg.csv', mode='a', index=False, header=False)\n",
    "        final_df = pd.DataFrame(columns = ['job_title', 'company', 'salary', 'job_type', 'years_experience', 'tech_stack', \n",
    "                                 'job_description', 'industry', 'function', 'roles', 'last_updated', 'posted_on'])\n",
    "        count = 0\n",
    "    \n",
    "        \n",
    "final_df.to_csv('./Posts_MonsterSg.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2663c1f2",
   "metadata": {},
   "source": [
    "### If crash halfway, run the code below before changing the start index in the prev cell to where it stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e14f418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79e4d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append data to the csv\n",
    "\n",
    "final_df.to_csv('./Posts_MonsterSg.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1bed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset final_df table \n",
    "\n",
    "final_df = pd.DataFrame(columns = ['job_title', 'company', 'salary', 'job_type', 'years_experience', 'tech_stack', \n",
    "                                 'job_description', 'industry', 'function', 'roles', 'last_updated', 'posted_on'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93b2804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the start index to the following result\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a850a2",
   "metadata": {},
   "source": [
    "# Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0316a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update directory\n",
    "check_df = pd.read_csv('./Posts_MonsterSg.csv')\n",
    "check_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5212deee",
   "metadata": {},
   "source": [
    "### If first few roles are empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d8bb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df.dropna(how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0470aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28220fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: overwrites the current file \n",
    "# change the directory & name to the one that you saved\n",
    "\n",
    "check_df.to_csv('./Posts_MonsterSg.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
