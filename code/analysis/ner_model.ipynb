{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "nlp=spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "# Getting the ner component\n",
    "ner=nlp.get_pipe('ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training Data with New Label (SKILL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using code to find the start and end index of each identified entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: 277\n",
      "end: 300\n"
     ]
    }
   ],
   "source": [
    "text = \"Hands-on experience with Java/Web frameworks and tools including Java/JEE, Python, Spring Boot Framework, Redis/Aerospike, ReactJS, Kafka, MongoDB, Cloud Foundry or similar cloud technology (AWS) DevOps and CICD knowledge e.g., Git, Jenkins, Sonar Qube, Docker, unit test- and Test-driven development\"\n",
    "\n",
    "word = \"Test-driven development\"\n",
    "text.index(word)\n",
    "end_index = len(word) + text.index(word)\n",
    "\n",
    "print(\"start:\", text.index(word))\n",
    "print(\"end:\", end_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = \"SKILL\"\n",
    "\n",
    "TRAINING_DATA = [\n",
    "    ('Hands-on experience with Java/Web frameworks and tools including Java/JEE, Python, Spring Boot Framework, Redis/Aerospike, ReactJS, Kafka, MongoDB, Cloud Foundry or similar cloud technology (AWS) DevOps and CICD knowledge e.g., Git, Jenkins, Sonar Qube, Docker, unit test- and Test-driven development', {'entities': [(25,33, 'SKILL'), (75,81, 'SKILL'),(83,104, 'SKILL'),(106,111, 'SKILL'),(112,121, 'SKILL'),(123,130, 'SKILL'),(132,137, 'SKILL'),(139,146, 'SKILL'),(148,161, 'SKILL'),(191,194, 'SKILL'),(196,202, 'SKILL'),(207,211, 'SKILL'),(228,231, 'SKILL'),(233,240, 'SKILL'),(242,252, 'SKILL'),(254,260, 'SKILL'),(277,300, 'SKILL')]}), \n",
    "    \n",
    "    ('Familiarity with the database technologies, preferably MariaDB, MySQL, NoSQL', {'entities': [(55,62, 'SKILL'), (64,69, 'SKILL'), (71,76, 'SKILL')]}),\n",
    "    \n",
    "    ('We run our systems on GCP with GKE and our media pipeline on AWS. We also use Spinnaker, Cloudbuild, ELK, PostgreSQL, Redis to name a few tools. ', {'entities': [(61,63, 'SKILL'), (78,87, 'SKILL'), (89,99, 'SKILL'), (101,104, 'SKILL'), (106,116, 'SKILL')]}),\n",
    "\n",
    "    ('A solid foundation in understanding of practical operating system concepts around Linux/ Unix and grasp of basic networking are essential', {'entities': [(82,87, 'SKILL'), (89,93, 'SKILL')]}),\n",
    "\n",
    "    ('Familiarity with Docker / Kubernetes or any equivalent systems is a must. ', {'entities': [(17,23, 'SKILL'), (26,36, 'SKILL')]}),\n",
    "\n",
    "    ('Familiarity with either AWS or GCP or Azure is a must', {'entities': [(24,27, 'SKILL'), (38,43, 'SKILL')]}), \n",
    "\n",
    "    ('1 year of experience in AWS infrastructure, CI/D, and familiarity with at least some of the following', {'entities': [(24,27, 'SKILL'), (44,48, 'SKILL')]}),\n",
    "\n",
    "    ('Coordinate DevOps processes focusing on continuous integration and delivery.', {'entities': [(40,75, 'SKILL')]}),\n",
    "\n",
    "    ('Evaluate third-party services and determine feasibility of integration with CI/CD pipeline.', {'entities': [(76,81, 'SKILL')]}),\n",
    "\n",
    "    ('Perform occasional light-weight database management and configuration.', {'entities': [(32,51, 'SKILL')]}),\n",
    "\n",
    "    ('Provide support/consultancy to other engineers in activities such as solutioning, troubleshooting.', {'entities': [(69,80, 'SKILL'), (82,97, 'SKILL')]}),\n",
    "\n",
    "    ('Hosting/cloud platforms: AWS, Azure, GCP', {'entities': [(25,28, 'SKILL'), (30,35, 'SKILL'), (37,40, 'SKILL')]}),\n",
    "\n",
    "    ('Code: Shell scripting, TypeScript, JavaScript', {'entities': [(6,21, 'SKILL'), (23,33, 'SKILL'), (35,45, 'SKILL')]}),\n",
    "\n",
    "    ('Logging: FluentD, ElasticSearch, CloudWatch', {'entities': [(9,16, 'SKILL'), (18,31, 'SKILL') ,(33,43, 'SKILL')]}),\n",
    "\n",
    "    ('Telemetry: Prometheus', {'entities': [(11,21, 'SKILL')]}),\n",
    "\n",
    "    ('Participate and contribute to technical solutioning and architecture reviews with architecture team', {'entities': [(30,51, 'SKILL'), (56,76, 'SKILL')]}),\n",
    "\n",
    "    ('Good understanding of open-source software development and related automation tools (e.g., Terraform, Ansible, Nexus, Jenkins, SonarQube, Git, Artifactory)', {'entities': [(91,100, 'SKILL') ,(102,109, 'SKILL'), (111,116, 'SKILL')]}),\n",
    "\n",
    "    ('Experience in implementing and maintaining complex CI/CD pipelines', {'entities': [(51,56, 'SKILL')]}),\n",
    "\n",
    "    ('Good understanding of cloud computing/container deployment and management such as AWS/Azure/OpenStack/Kubernetes(K8s) etc.', {'entities': [(22,37, 'SKILL'), (38,58, 'SKILL'), (82,85, 'SKILL'), (86,91, 'SKILL'), (92,101, 'SKILL'), (102,112, 'SKILL')]}),\n",
    "\n",
    "    ('There is a substantial focus on advanced (hands-on) expertise in Microsoft Azure Data Platform, Azure Data Factory, Azure Data Warehousing, Azure Synapse and Data Services.', {'entities': [(65,94, 'SKILL'), (96,114, 'SKILL'), (116,138, 'SKILL'), (140,171, 'SKILL')]}),\n",
    "\n",
    "    ('2+ years of experience in any of the following Data Platform Cloud solutions:Big Data and Data Warehouses including Azure Synapse Analytics (formerly Azure SQL DW), Snowflake, GCP Big Query, AWS RedshiftAdvanced Analytics including Azure Synapse Analytics, Azure Data Bricks, data visualization tools', {'entities': [(47,76, 'SKILL'), (116,139, 'SKILL'), (165,174, 'SKILL'), (176,189, 'SKILL'), (191,203, 'SKILL')]}),\n",
    "\n",
    "    ('Advanced Analytics including Azure Synapse Analytics, Azure Data Bricks, data visualization tools', {'entities': [(29,52, 'SKILL'), (54,71, 'SKILL'), (73,97, 'SKILL')]}),\n",
    "\n",
    "    ('You will collaborate with customers, partners and other AWS teams to craft architectures, proof of concepts and demonstrations of our platform that work back from customer\\'s business needs and accelerate the adoption of appropriate AWS technology.', {'entities': [(69,88, 'SKILL')]}),\n",
    "\n",
    "    ('Experience architecting, migrating or transforming customer requirements to the cloud ', {'entities': [(11,72, 'SKILL')]}),\n",
    "\n",
    "    ('Professional experience architecting/operating solutions built on AWS', {'entities': [(66,69, 'SKILL')]}),\n",
    "\n",
    "    ('Advanced working SQL knowledge and experience working with RDBMS, Hadoop and NoSQL', {'entities': [(17,20, 'SKILL'), (59,64, 'SKILL'), (66,72, 'SKILL'), (77,82, 'SKILL')]}),\n",
    "\n",
    "    ('Leverages a structured approach to Architecture Projects using existing methodologies (e.g., Waterfall, Agile, Iterative) that make use of existing reference architecture and established architectural styles and design patterns.', {'entities': [(93,102, 'SKILL'), (104,109, 'SKILL'), (111,120, 'SKILL')]}),\n",
    "\n",
    "    ('Experience in DevOps or DevSecOps', {'entities': [(14,20, 'SKILL'), (24,33, 'SKILL')]}),\n",
    "\n",
    "    ('Strong track record of implementing AWS services in a variety of distributed computing environments', {'entities': [(36,39, 'SKILL')]}),\n",
    "\n",
    "    ('Build a strong foundation of knowledge around AWS cloud services and the cloud ecosystem', {'entities': [(46,49, 'SKILL')]}),\n",
    "\n",
    "    ('Proficiency with one or more programming languages (e.g., Python, JavaScript, C#, Java).', {'entities': [(58,64, 'SKILL'), (66,70, 'SKILL')]}),\n",
    "\n",
    "    ('AWS certification (e.g. AWS Solutions Architect Associate or Professional) or other cloud industry certification', {'entities': [(0,3, 'SKILL'), (24,57, 'SKILL')]}), \n",
    "\n",
    "    ('Strong expertise in AWS Architecture design', {'entities': [(20,42, 'SKILL')]}), \n",
    "\n",
    "    ('Strong experience in AWS - Certification at Professional Level Certification is preferred', {'entities': [(21,24, 'SKILL'), (27,63, 'SKILL')]}),\n",
    "\n",
    "    ('Demonstrates some knowledge and/or a proven record of success in the consulting industry, especially relating to business processes that are enabled by identity and access management solutions, including the following areas: Requirements analysis, strategy, design, and migration for businesses LDAP, Identity and Access technology concepts and understanding of software development 3-4 years of in-depth experience working with IAM products for on-premise and Cloud deployments on Microsoft Azure and Amazon Web Services (AWS) environments', {'entities': [(225,246, 'SKILL'), (270,299, 'SKILL'), (301,340, 'SKILL')]}), \n",
    "\n",
    "    ('Utilizing and applying knowledge of the Identity Management suite of products (SailPoint, Okta, CyberArk, and other comparable products), design solutioning and implementation into projects', {'entities': [(40,59, 'SKILL'), (79,88, 'SKILL'), (90,94, 'SKILL'), (96,104, 'SKILL')]}), \n",
    "\n",
    "    ('Familiarity to Azure/AWS Cloud Service Providers technology concepts', {'entities': [(15,20, 'SKILL'), (21,24, 'SKILL')]}), \n",
    "\n",
    "    ('Working Knowledge in Python, C++, Java and/or Power Shell would be highly advantageous', {'entities': [(21,27, 'SKILL'), (29,32, 'SKILL'), (46,57, 'SKILL')]}),\n",
    "\n",
    "    ('direct experience with SIEM, PAM, Intrusion Detection Systems, firewalls, DLP and email/ web content filtering would be an advantage', {'entities': [(23,27, 'SKILL'), (29,32, 'SKILL'), (34,61, 'SKILL'), (63,72, 'SKILL')]}), \n",
    "\n",
    "    ('Good in-depth knowledge of cloud-based technologies (e.g. EMR, Redshift, S3, etc.)', {'entities': [(58,61, 'SKILL'), (63,71, 'SKILL'), (73,75, 'SKILL')]}),\n",
    "\n",
    "    ('Develop applications using Java and JavaScript', {'entities': [(27,31, 'SKILL'), (36,46, 'SKILL')]}),\n",
    "\n",
    "    ('You will be working in team within the Wealth Management division developing an advisory platform using the state-of-the-art technologies in the Azure Cloud', {'entities': [(145,156, 'SKILL')]}), \n",
    "\n",
    "    ('Proficient skills with tools used in software development lifecycle, such as IntelliJ IDEA or Eclipse, JIRA, GitLab, Maven, Teamcity, etc.', {'entities': [(77,90, 'SKILL'), (94,101, 'SKILL'), (103,107, 'SKILL'), (109,115, 'SKILL'), (117,122, 'SKILL')]}),\n",
    "\n",
    "    ('We are looking for highly skilled programmers with experience building applications in Java', {'entities': [(87,91, 'SKILL')]}),\n",
    "    \n",
    "    ('Experience of using relational database, like JDBC, SQL, Store Procedure.', {'entities': [(20,39, 'SKILL'),(46,50, 'SKILL'),(52,55, 'SKILL'),(57,72, 'SKILL')]}),\n",
    "\n",
    "    ('Awareness of Docker, Ansible, Kubernetes, Splunk, Public Cloud management', {'entities': [(13,19, 'SKILL'),(21,28, 'SKILL'),(30,40, 'SKILL'),(42,48, 'SKILL'),(50,73, 'SKILL')]}),\n",
    "\n",
    "    ('Deep understanding of vulnerability scanning tools like Qualys, Contrast, Fortify etc.', {'entities': [(56,62, 'SKILL'),(64,72, 'SKILL'),(74,81, 'SKILL')]}),\n",
    "\n",
    "    ('5 years Experience in Spring boot/ Swagger / Open API3', {'entities': [(22,32, 'SKILL'),(35,41, 'SKILL'),(45,53, 'SKILL')]}),\n",
    "\n",
    "    ('Working experience in Unix shell scripting, Perl scripting, Pivotal Cloud Foundry (PCF) and Ansible playbook for deployment', {'entities': [(22,42, 'SKILL'),(60,87, 'SKILL'),(92,108, 'SKILL')]}),\n",
    "\n",
    "    ('5 years of experience in enterprise application and system design with OOA/OOD, UML Modeling Project / hands-on experience with J2EE standard', {'entities': [(25,47, 'SKILL'),(71,78, 'SKILL'),(80,100, 'SKILL'),(128,132, 'SKILL')]}),\n",
    "\n",
    "    ('Deep knowledge of Salesforce application architecture & design, Salesforce lightning, Salesforce integrations, Service Cloud customisation and custom development.', {'entities': [(18,62, 'SKILL'),(64,84, 'SKILL'),(86,109, 'SKILL'),(111,138, 'SKILL')]}),\n",
    "\n",
    "    ('Knowledge of implementing MuleSoft to extend the Salesforce integrations', {'entities': [(26,34, 'SKILL'),(49,72, 'SKILL')]}),\n",
    "\n",
    "    ('AWS and Kubernetes experience is a must', {'entities': [(0,3, 'SKILL'),(8,18, 'SKILL')]}),\n",
    "\n",
    "    ('Familiar with the operating mechanism and principle of Kubernetes', {'entities': [(55,65, 'SKILL')]}),\n",
    "\n",
    "    ('Experience with Docker runtime, Linux kernel is a plus', {'entities': [(16,22, 'SKILL'),(32,37, 'SKILL')]}),\n",
    "\n",
    "    ('Experience with Amazon EKS services is a plus', {'entities': [(16,35, 'SKILL')]}),\n",
    "\n",
    "    ('Responsibilities include contribution to several facets of backend development and DevOps: i.e., backend design, infrastructure setup, managing DevOps pipelines, troubleshooting technical issues', {'entities': [(59,78, 'SKILL'),(83,89, 'SKILL'),(113,133, 'SKILL'),(135,160, 'SKILL'),(162,194, 'SKILL')]}),\n",
    "\n",
    "    ('Building and maintaining cloud resources on platforms like Microsoft Azure or Alibaba Cloud Build and troubleshoot application builds and deployment using DevOps pipelines', {'entities': [(59,74, 'SKILL'),(78,97, 'SKILL'),(102,114, 'SKILL'),(155,171, 'SKILL')]}),\n",
    "\n",
    "    ('Experience working with Microsoft Azure (Alibaba Cloud is a plus) ', {'entities': [(24,39, 'SKILL'),(41,52, 'SKILL')]}),\n",
    "\n",
    "    ('Experience with containerization using Docker and Kubernetes ', {'entities': [(16,32, 'SKILL'),(39,45, 'SKILL'),(50,60, 'SKILL')]}),\n",
    "\n",
    "    ('5+ years of strong programming skills (at least 2 years of in-depth NestJS experience) ', {'entities': [(68,74, 'SKILL')]}),\n",
    "\n",
    "    ('Solid knowledge of a relational database system like PostgreSQL', {'entities': [(53,63, 'SKILL')]}),\n",
    "\n",
    "    ('proven ability to consume and create secure RESTful APIs to facilitate integration', {'entities': [(44,56, 'SKILL')]}),\n",
    "\n",
    "    ('Total comfort leveraging JIRA and Confluence for documenting architectural and development decisions in an iterative manner', {'entities': [(25,29, 'SKILL'),(34,44, 'SKILL')]}),\n",
    "\n",
    "    ('Proficiency is required in at least 2 of the following software languages Ansible, Python, JavaScript, vRealize Automation (vRA) / vRealize Orchestrator (vRO), and/or PowerCLI Source code management with GIT / BitBucket and proficiency with source code branching strategies', {'entities': [(74,81, 'SKILL'),(83,89, 'SKILL'),(91,101, 'SKILL'),(103,128, 'SKILL'),(131,158, 'SKILL'),(167,198, 'SKILL'), (204,207, 'SKILL')]}),\n",
    "\n",
    "    ('Bachelor\\'s degree and 8+ years of hands-on experience developing applications using Java/J2EE, with Spring boot framework knowledge and experience', {'entities': [(84,88, 'SKILL'),(89,93, 'SKILL'),(100,121, 'SKILL')]}),\n",
    "\n",
    "    ('Experience with containerization and cloud technologies (eg. OpenShift, Kubernetes, Dockers, Mesos, AWS) as well as DevOps and testing tools (Git, SVN, TFS, Jira, Confluence, Jenkins, Nexus, Selenium, SonarQube)', {'entities': [(16,32, 'SKILL'),(61,70, 'SKILL'),(72,82, 'SKILL'),(84,91, 'SKILL'),(93,98, 'SKILL'),(175,182, 'SKILL')]}),\n",
    "\n",
    "    ('', {'entities': [(116,122, 'SKILL'),(142,145, 'SKILL'),(147,148, 'SKILL'),(152,155, 'SKILL'),(163,173, 'SKILL')]}),\n",
    "\n",
    "    ('Prior Experience on RFPs, RFQs, estimations and other similar Technical Documentation is a plus. UiPath Certified Professionals ( UCP ) preferred.', {'entities': [(20,24, 'SKILL'),(26,30, 'SKILL'),(62,85, 'SKILL'),(97,135, 'SKILL')]}), \n",
    "\n",
    "    ('Basic Knowledge on UiPath Deployment Architecture and Cloud platforms Azure/AWS', {'entities': [(19,49, 'SKILL'),(54,74, 'SKILL'),(76,78, 'SKILL')]}), \n",
    "\n",
    "    ('Experience in infrastructure-related technology is preferred, i.e., application server infrastructure, cloud platforms (Azure/AWS/GCP), credential management, etc.', {'entities': [(68,101, 'SKILL'),(120,125, 'SKILL'),(126,129, 'SKILL'),(130,133, 'SKILL'),(136,157, 'SKILL')]}),\n",
    "\n",
    "    ('UiPath RPA Solution Architect Certification and Advanced Developer Certification a must.', {'entities': [(0,43, 'SKILL'),(48,80, 'SKILL')]}), \n",
    "\n",
    "    ('Experience in a high-level programing language such as Python, Golang or Java', {'entities': [(55,61, 'SKILL'),(63,69, 'SKILL'),(73,77, 'SKILL')]}),\n",
    "\n",
    "    ('Certifications: Core Cloud Certification, Salesforce Architect related certifications and Mulesoft Certification', {'entities': [(16,40, 'SKILL'),(42,62, 'SKILL'),(90,112, 'SKILL')]}),\n",
    "\n",
    "    ('Knowledge to Web development skills including CSS, JavaScript, HTML, XML are added advantage', {'entities': [(46,49, 'SKILL'),(51,61, 'SKILL'),(63,67, 'SKILL'),(69,72, 'SKILL')]}),\n",
    "\n",
    "    ('Familiarity to Azure/AWS Cloud Service Providers technology concepts ', {'entities': [(15,20, 'SKILL'),(21,24, 'SKILL')]}),\n",
    "\n",
    "    ('3-4 years of in-depth experience working with IAM products for on-premise and Cloud deployments on Microsoft Azure and Amazon Web Services (AWS) environments', {'entities': [(46,49, 'SKILL'),(99,114, 'SKILL'),(119,138, 'SKILL')]}),\n",
    "\n",
    "    ('Certification in TOGAF or other formal architecture frameworks is desired.', {'entities': [(17,22, 'SKILL')]}),\n",
    "\n",
    "    ('Hands-on experience developing solutions using one or more web / mobile application framework and / or tools E.g. Cordova, Adobe AEM, Chorme DevTools, KAFKA, Bootstrap (or similar), AngularJS, Weblogic / Websphere (or similar web application server), CDN solutions, etc ', {'entities': [(114,121, 'SKILL'),(123,132, 'SKILL'),(134,149, 'SKILL'),(151,156, 'SKILL'),(158,167, 'SKILL'),(182,191, 'SKILL')]}),\n",
    "\n",
    "    ('Worked with Automation tools (E.g. Selenium, SOAPUI, Bamboo, Jenkins, Ansible, Marvin, Github, Bitbucket, etc.)', {'entities': [(35,43, 'SKILL'),(45,51, 'SKILL'),(53,59, 'SKILL'),(61,68, 'SKILL'),(70,77, 'SKILL'),(79,85, 'SKILL'),(87,93, 'SKILL'),(95,104, 'SKILL')]}),\n",
    "\n",
    "    ('Experience with iOS mobile apps management/ development, Apple HIG, ApplePay and other related services in the apple ecosystem is required.', {'entities': [(16,55, 'SKILL'),(57,66, 'SKILL'),(68,76, 'SKILL')]}),\n",
    "\n",
    "    ('Working knowledge of application design frameworks, UML or equivalent design artifacts is required.', {'entities': [(21,50, 'SKILL'),(52,55, 'SKILL')]}),\n",
    "\n",
    "    ('Firm understanding of web / mobile security E.g. web vulnerability, native apps security, authentication mechanism, session management, application-level encryption, PKI, application signing, cross-site scripting, OWASP, etc ', {'entities': [(22,43, 'SKILL'),(49,66, 'SKILL'),(68,88, 'SKILL'),(90,114, 'SKILL'),(116,134, 'SKILL'),(136,164, 'SKILL'),(166,169, 'SKILL'),(171,190, 'SKILL'),(192,212, 'SKILL'),(214,219, 'SKILL')]}),\n",
    "\n",
    "    ('Familiar with enterprise architecture concepts like SOA, API integration, micro-services architecture, micro-FE / micro-app, service-centric design. ', {'entities': [(52,55, 'SKILL'),(57,72, 'SKILL'),(74,101, 'SKILL'),(103,111, 'SKILL'),(114,123, 'SKILL'),(125,147, 'SKILL')]}),\n",
    "\n",
    "    ('Hands-on development experience using REST, SOAP, web services and/or other web protocols for application integration.', {'entities': [(38,42, 'SKILL'),(44,48, 'SKILL'),(50,62, 'SKILL'),(76,89, 'SKILL')]})\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training new entity type in spaCy NER Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new label to ner\n",
    "ner.add_label(LABEL)\n",
    "\n",
    "# Resume training\n",
    "optimizer = nlp.resume_training()\n",
    "move_names = list(ner.move_names)\n",
    "\n",
    "# List of pipes you want to train\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "\n",
    "# List of pipes which should remain unaffected in training\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 3.553951868962846}\n",
      "Losses {'ner': 10.649881359977075}\n",
      "Losses {'ner': 15.900161093322343}\n",
      "Losses {'ner': 30.021390079604586}\n",
      "Losses {'ner': 34.97250647185581}\n",
      "Losses {'ner': 40.61387388782808}\n",
      "Losses {'ner': 40.617166689183364}\n",
      "Losses {'ner': 46.7068974993055}\n",
      "Losses {'ner': 46.7068974993055}\n",
      "Losses {'ner': 46.70701176758636}\n",
      "Losses {'ner': 49.80130989387168}\n",
      "Losses {'ner': 49.99486149026065}\n",
      "Losses {'ner': 59.111799158928875}\n",
      "Losses {'ner': 62.35113624748961}\n",
      "Losses {'ner': 64.02509201810167}\n",
      "Losses {'ner': 70.56815579021085}\n",
      "Losses {'ner': 77.30684706867149}\n",
      "Losses {'ner': 80.3257551877349}\n",
      "Losses {'ner': 83.61037370489733}\n",
      "Losses {'ner': 89.83142283586227}\n",
      "Losses {'ner': 94.17948268329485}\n",
      "Losses {'ner': 96.17997516451172}\n",
      "Losses {'ner': 98.16219332426607}\n",
      "Losses {'ner': 99.62344420549267}\n",
      "Losses {'ner': 106.33269549439193}\n",
      "Losses {'ner': 117.26086311315083}\n",
      "Losses {'ner': 121.96878744432405}\n",
      "Losses {'ner': 132.24835208870735}\n",
      "Losses {'ner': 138.02933486994306}\n",
      "Losses {'ner': 141.74672088912092}\n",
      "Losses {'ner': 146.8395077357832}\n",
      "Losses {'ner': 152.65497194966932}\n",
      "Losses {'ner': 156.17498475616642}\n",
      "Losses {'ner': 161.31948085568413}\n",
      "Losses {'ner': 171.90519117915076}\n",
      "Losses {'ner': 176.62388029063234}\n",
      "Losses {'ner': 182.9503526241397}\n",
      "Losses {'ner': 184.30818797376654}\n",
      "Losses {'ner': 185.62874832667706}\n",
      "Losses {'ner': 186.88305067270824}\n",
      "Losses {'ner': 210.37091236705058}\n",
      "Losses {'ner': 213.4637685181024}\n",
      "Losses {'ner': 214.59643209764366}\n",
      "Losses {'ner': 218.71224086199985}\n",
      "Losses {'ner': 225.8997932902512}\n",
      "Losses {'ner': 228.47767227045009}\n",
      "Losses {'ner': 229.59662405831526}\n",
      "Losses {'ner': 232.91197900055752}\n",
      "Losses {'ner': 238.8726793105093}\n",
      "Losses {'ner': 245.8463377555095}\n",
      "Losses {'ner': 247.27839549777175}\n",
      "Losses {'ner': 249.82849580638188}\n",
      "Losses {'ner': 255.38948273246254}\n",
      "Losses {'ner': 257.3018643860346}\n",
      "Losses {'ner': 262.1106694762352}\n",
      "Losses {'ner': 265.4680719426474}\n",
      "Losses {'ner': 270.96971992321096}\n",
      "Losses {'ner': 279.6029877026381}\n",
      "Losses {'ner': 281.11983033507613}\n",
      "Losses {'ner': 283.2229778746191}\n",
      "Losses {'ner': 285.28442622205375}\n",
      "Losses {'ner': 293.8849085361585}\n",
      "Losses {'ner': 295.8813379788194}\n",
      "Losses {'ner': 301.4317824192699}\n",
      "Losses {'ner': 303.72268582447623}\n",
      "Losses {'ner': 307.9941607250662}\n",
      "Losses {'ner': 308.84341096272374}\n",
      "Losses {'ner': 311.06298251267935}\n",
      "Losses {'ner': 312.8203750574953}\n",
      "Losses {'ner': 314.7301270958028}\n",
      "Losses {'ner': 315.3559370433949}\n",
      "Losses {'ner': 363.53869996813125}\n",
      "Losses {'ner': 366.84964797562174}\n",
      "Losses {'ner': 369.30553354767386}\n",
      "Losses {'ner': 372.15695748034585}\n",
      "Losses {'ner': 375.98585003233205}\n",
      "Losses {'ner': 378.52957564528}\n",
      "Losses {'ner': 384.5739947583227}\n",
      "Losses {'ner': 385.43774511019484}\n",
      "Losses {'ner': 387.5644509062552}\n",
      "Losses {'ner': 391.12297738086994}\n",
      "Losses {'ner': 394.82935668807585}\n",
      "Losses {'ner': 408.5154882881998}\n",
      "Losses {'ner': 410.2019420066375}\n",
      "Losses {'ner': 412.0578759173185}\n"
     ]
    }
   ],
   "source": [
    "# Importing requirements\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.training.example import Example\n",
    "import random\n",
    "\n",
    "# Begin training by disabling other pipeline components\n",
    "with nlp.disable_pipes(*other_pipes) :\n",
    "\n",
    "    sizes = compounding(1.0, 4.0, 1.001)\n",
    "    # Training for 50 iterations     \n",
    "    for itn in range(50):\n",
    "    # shuffle examples before training\n",
    "        random.shuffle(TRAINING_DATA)\n",
    "    # batch up the examples using spaCy's minibatch\n",
    "    batches = minibatch(TRAINING_DATA, size=sizes)\n",
    "    # Dictionary to store losses\n",
    "    losses = {}\n",
    "    for batch in batches:\n",
    "        for text, annotations in batch:\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, annotations)\n",
    "            # Calling update() over the iteration\n",
    "            nlp.update([example], sgd=optimizer, drop=0.35, losses=losses)\n",
    "            print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### TOKENS\n",
      "Certifications\n",
      ":\n",
      "Core\n",
      "Cloud\n",
      "Certification\n",
      ",\n",
      "Salesforce\n",
      "Architect\n",
      "related\n",
      "certifications\n",
      "and\n",
      "Mulesoft\n",
      "Certification\n",
      "Minimum\n",
      "5\n",
      "years\n",
      "of\n",
      "experience\n",
      "blend\n",
      "of\n",
      "business\n",
      "and\n",
      "technical\n",
      "solution\n",
      "experience\n",
      "in\n",
      "solutioning\n",
      "and\n",
      "leading\n",
      "large\n",
      "Salesforce\n",
      "cloud\n",
      "implementation\n",
      "programs\n",
      "Experience\n",
      "in\n",
      "architecting\n",
      "solutions\n",
      "for\n",
      "different\n",
      "Salesforce\n",
      "Core\n",
      "Cloud\n",
      "(\n",
      "Marketing\n",
      ",\n",
      "Sales\n",
      ",\n",
      "Service\n",
      ",\n",
      "Community\n",
      ",\n",
      "etc\n",
      ")\n",
      "implementation\n",
      "and\n",
      "integration\n",
      "projects\n",
      "&\n",
      "proposals\n",
      "Experience\n",
      "in\n",
      "Salesforce\n",
      "strategy\n",
      ",\n",
      "roadmap\n",
      "design\n",
      ",\n",
      "crafting\n",
      "technical\n",
      "proposals\n",
      "and\n",
      "responding\n",
      "to\n",
      "RFIs\n",
      "and\n",
      "RFPs\n",
      "Experience\n",
      "in\n",
      "developing\n",
      "high\n",
      "-\n",
      "level\n",
      "architecture\n",
      "design\n",
      "of\n",
      "current\n",
      "and\n",
      "future\n",
      "state\n",
      "solution\n",
      "based\n",
      "on\n",
      "business\n",
      "requirements\n",
      "and\n",
      "value\n",
      "propositions\n",
      "Minimum\n",
      "5\n",
      "years\n",
      "of\n",
      "experience\n",
      "in\n",
      "consulting\n",
      "work\n",
      "â€\n",
      "“\n",
      "preferably\n",
      "for\n",
      "top\n",
      "consulting\n",
      "companies\n",
      "Experience\n",
      "with\n",
      "Data\n",
      "modelling\n",
      ",\n",
      "SQL\n",
      ",\n",
      "integration\n",
      "with\n",
      "Web\n",
      "Services\n",
      "(\n",
      "SOAP\n",
      "/\n",
      "REST\n",
      "/\n",
      "XML\n",
      ")\n",
      ")\n",
      "WS-\n",
      "*\n",
      "stack\n",
      "and\n",
      "WSDL\n",
      "are\n",
      "added\n",
      "advantage\n",
      "to\n",
      "support\n",
      "user\n",
      "testing\n",
      "Knowledge\n",
      "of\n",
      "software\n",
      "development\n",
      "fundamentals\n",
      "such\n",
      "as\n",
      ":\n",
      "knowledge\n",
      "of\n",
      "data\n",
      "structures\n",
      ",\n",
      "object\n",
      "-\n",
      "oriented\n",
      "programming\n",
      ",\n",
      "relational\n",
      "database\n",
      "design\n",
      ",\n",
      "and\n",
      "design\n",
      "patterns\n",
      "Knowledge\n",
      "to\n",
      "Web\n",
      "development\n",
      "skills\n",
      "including\n",
      "CSS\n",
      ",\n",
      "JavaScript\n",
      ",\n",
      "HTML\n",
      ",\n",
      "XML\n",
      "are\n",
      "added\n",
      "advantage\n",
      "An\n",
      "ability\n",
      "to\n",
      "articulate\n",
      "and\n",
      "clearly\n",
      "communicate\n",
      "complex\n",
      "problems\n",
      "and\n",
      "solutions\n",
      "in\n",
      "a\n",
      "simple\n",
      ",\n",
      "visual\n",
      "and\n",
      "impactful\n",
      "manner\n",
      "Proven\n",
      "ability\n",
      "to\n",
      "build\n",
      ",\n",
      "manage\n",
      "and\n",
      "foster\n",
      "a\n",
      "team\n",
      "-\n",
      "orientated\n",
      "environment\n",
      "Excellent\n",
      "communication\n",
      "(\n",
      "written\n",
      "and\n",
      "oral\n",
      ")\n",
      ",\n",
      "storytelling\n",
      ",\n",
      "presentation\n",
      "and\n",
      "interpersonal\n",
      "skills\n",
      "Excellent\n",
      "leadership\n",
      "and\n",
      "management\n",
      "skills\n",
      "####### ENTITIES\n",
      "Entities in 'Certifications: Core Cloud Certification, Salesforce Architect related certifications and Mulesoft Certification Minimum 5 years of experience blend of business and technical solution experience in solutioning and leading large Salesforce cloud implementation programs Experience in architecting solutions for different Salesforce Core Cloud (Marketing, Sales, Service, Community, etc) implementation and integration projects & proposals Experience in Salesforce strategy, roadmap design, crafting technical proposals and responding to RFIs and RFPs Experience in developing high-level architecture design of current and future state solution based on business requirements and value propositions Minimum 5 years of experience in consulting work â€“ preferably for top consulting companies Experience with Data modelling, SQL, integration with Web Services (SOAP / REST / XML)) WS-* stack and WSDL are added advantage to support user testing Knowledge of software development fundamentals such as: knowledge of data structures, object-oriented programming, relational database design, and design patterns Knowledge to Web development skills including CSS, JavaScript, HTML, XML are added advantage An ability to articulate and clearly communicate complex problems and solutions in a simple, visual and impactful manner Proven ability to build, manage and foster a team-orientated environment Excellent communication (written and oral), storytelling, presentation and interpersonal skills Excellent leadership and management skills'\n",
      "('Salesforce', 'SKILL')\n",
      "('Mulesoft', 'SKILL')\n",
      "('Salesforce', 'SKILL')\n",
      "('Marketing', 'SKILL')\n",
      "('Sales', 'SKILL')\n",
      "('Service', 'SKILL')\n",
      "('Community', 'SKILL')\n",
      "('Salesforce', 'SKILL')\n",
      "('Data', 'SKILL')\n",
      "('SQL', 'SKILL')\n",
      "('Web Services', 'SKILL')\n",
      "('SOAP', 'SKILL')\n",
      "('REST', 'SKILL')\n",
      "('XML', 'SKILL')\n",
      "('CSS', 'SKILL')\n",
      "('JavaScript', 'SKILL')\n",
      "('HTML', 'SKILL')\n",
      "('XML', 'SKILL')\n",
      "('Excellent', 'SKILL')\n",
      "('Excellent', 'SKILL')\n"
     ]
    }
   ],
   "source": [
    "# Testing the NER\n",
    "\n",
    "test_text = \"Certifications: Core Cloud Certification, Salesforce Architect related certifications and Mulesoft Certification Minimum 5 years of experience blend of business and technical solution experience in solutioning and leading large Salesforce cloud implementation programs Experience in architecting solutions for different Salesforce Core Cloud (Marketing, Sales, Service, Community, etc) implementation and integration projects & proposals Experience in Salesforce strategy, roadmap design, crafting technical proposals and responding to RFIs and RFPs Experience in developing high-level architecture design of current and future state solution based on business requirements and value propositions Minimum 5 years of experience in consulting work â€“ preferably for top consulting companies Experience with Data modelling, SQL, integration with Web Services (SOAP / REST / XML)) WS-* stack and WSDL are added advantage to support user testing Knowledge of software development fundamentals such as: knowledge of data structures, object-oriented programming, relational database design, and design patterns Knowledge to Web development skills including CSS, JavaScript, HTML, XML are added advantage An ability to articulate and clearly communicate complex problems and solutions in a simple, visual and impactful manner Proven ability to build, manage and foster a team-orientated environment Excellent communication (written and oral), storytelling, presentation and interpersonal skills Excellent leadership and management skills\"\n",
    "doc = nlp(test_text)\n",
    "\n",
    "#### Checking spaCy tokenization \n",
    "print(\"####### TOKENS\")\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "\n",
    "#### Extracting entities in text\n",
    "print(\"####### ENTITIES\")\n",
    "print(\"Entities in '%s'\" % test_text)\n",
    "for ent in doc.ents:\n",
    "    print((ent.text, ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/nodeflair/nodeflair_jobpostings.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nodeflair_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m../data/nodeflair/nodeflair_jobpostings.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, index_col\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m nodeflair_data\u001b[39m.\u001b[39mhead(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=664'>665</a>\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=665'>666</a>\u001b[0m     dialect,\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=666'>667</a>\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=675'>676</a>\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=676'>677</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=677'>678</a>\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=679'>680</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=571'>572</a>\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=573'>574</a>\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=574'>575</a>\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=576'>577</a>\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=577'>578</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=929'>930</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=931'>932</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=932'>933</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=1212'>1213</a>\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=1213'>1214</a>\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=1214'>1215</a>\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=1215'>1216</a>\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=1216'>1217</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=1217'>1218</a>\u001b[0m     f,\n\u001b[0;32m   <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=1218'>1219</a>\u001b[0m     mode,\n\u001b[0;32m   <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=1219'>1220</a>\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=1220'>1221</a>\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=1221'>1222</a>\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=1222'>1223</a>\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=1223'>1224</a>\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=1224'>1225</a>\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=1225'>1226</a>\u001b[0m )\n\u001b[0;32m   <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=1226'>1227</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/parsers/readers.py?line=1227'>1228</a>\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/common.py?line=783'>784</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/common.py?line=784'>785</a>\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/common.py?line=785'>786</a>\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/common.py?line=786'>787</a>\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/common.py?line=787'>788</a>\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/common.py?line=788'>789</a>\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/common.py?line=789'>790</a>\u001b[0m             handle,\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/common.py?line=790'>791</a>\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/common.py?line=791'>792</a>\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/common.py?line=792'>793</a>\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/common.py?line=793'>794</a>\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/common.py?line=794'>795</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/common.py?line=795'>796</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/common.py?line=796'>797</a>\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/user/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0/LocalCache/local-packages/Python39/site-packages/pandas/io/common.py?line=797'>798</a>\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/nodeflair/nodeflair_jobpostings.csv'"
     ]
    }
   ],
   "source": [
    "nodeflair_data = pd.read_csv(\"../\", index_col=0)\n",
    "nodeflair_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skills(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    return (ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeflair_data[\"extracted_skills\"] = nodeflair_data[\"Job Desc\"].apply(get_skills)\n",
    "nodeflair_data[[\"extracted_skills\"]]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38d51dd8e8d25c2b4859ddf5fde4d8615b38902fd48d30a19bf46ddb81d406a6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
